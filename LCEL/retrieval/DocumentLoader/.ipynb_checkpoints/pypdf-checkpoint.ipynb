{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2c8f40d-e1b4-49f9-a8bb-38914867d3ff",
   "metadata": {},
   "source": [
    "### PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2b8a2e-7afd-44ee-86dd-eb3d9de29fe9",
   "metadata": {},
   "source": [
    "## Using - Using PyPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7abfb0ac-0488-4fdc-98ef-060a2dd9eb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-3.17.4-py3-none-any.whl.metadata (7.5 kB)\n",
      "Downloading pypdf-3.17.4-py3-none-any.whl (278 kB)\n",
      "   ---------------------------------------- 0.0/278.2 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 194.6/278.2 kB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 278.2/278.2 kB 4.3 MB/s eta 0:00:00\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-3.17.4\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaa60514-f78c-447b-9101-2f3f7333aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ccee753-397d-4280-a3c8-d6a3646b2ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader('C:/Users/Owner/GenAI/LCEL/data/layout-parser-paper.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb0bdac4-6a6e-44cc-b58c-e930c6623bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66dc283e-00b5-4def-a4c2-110ea3160446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='LayoutParser : A Uniﬁed Toolkit for Deep\\nLearning Based Document Image Analysis\\nZejiang Shen1( \\x00), Ruochen Zhang2, Melissa Dell3, Benjamin Charles Germain\\nLee4, Jacob Carlson3, and Weining Li5\\n1Allen Institute for AI\\nshannons@allenai.org\\n2Brown University\\nruochen zhang@brown.edu\\n3Harvard University\\n{melissadell,jacob carlson }@fas.harvard.edu\\n4University of Washington\\nbcgl@cs.washington.edu\\n5University of Waterloo\\nw422li@uwaterloo.ca\\nAbstract. Recent advances in document image analysis (DIA) have been\\nprimarily driven by the application of neural networks. Ideally, research\\noutcomes could be easily deployed in production and extended for further\\ninvestigation. However, various factors like loosely organized codebases\\nand sophisticated model conﬁgurations complicate the easy reuse of im-\\nportant innovations by a wide audience. Though there have been on-going\\neﬀorts to improve reusability and simplify deep learning (DL) model\\ndevelopment in disciplines like natural language processing and computer\\nvision, none of them are optimized for challenges in the domain of DIA.\\nThis represents a major gap in the existing toolkit, as DIA is central to\\nacademic research across a wide range of disciplines in the social sciences\\nand humanities. This paper introduces LayoutParser , an open-source\\nlibrary for streamlining the usage of DL in DIA research and applica-\\ntions. The core LayoutParser library comes with a set of simple and\\nintuitive interfaces for applying and customizing DL models for layout de-\\ntection, character recognition, and many other document processing tasks.\\nTo promote extensibility, LayoutParser also incorporates a community\\nplatform for sharing both pre-trained models and full document digiti-\\nzation pipelines. We demonstrate that LayoutParser is helpful for both\\nlightweight and large-scale digitization pipelines in real-word use cases.\\nThe library is publicly available at https://layout-parser.github.io .\\nKeywords: Document Image Analysis ·Deep Learning ·Layout Analysis\\n·Character Recognition ·Open Source library ·Toolkit.\\n1 Introduction\\nDeep Learning(DL)-based approaches are the state-of-the-art for a wide range of\\ndocument image analysis (DIA) tasks including document image classiﬁcation [ 11,arXiv:2103.15348v2  [cs.CV]  21 Jun 2021', metadata={'source': 'C:/Users/Owner/GenAI/LCEL/data/layout-parser-paper.pdf', 'page': 0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86b23806-a5a3-450b-8a79-39487adc26e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76476d96-96ae-4a48-b32d-8881ed534a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55b72e4d-dbe0-4a43-8baa-e18433458679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9: 10 Z. Shen et al.\n",
      "Fig. 4: Illustration of (a) the original historical Japanese document with layout\n",
      "detection results and (b) a recreated version of the document image that achieves\n",
      "much better character recognition recall. The reorganization algorithm rearranges\n",
      "the tokens based on the their detect\n",
      "3: 4 Z. Shen et al.\n",
      "Efficient Data AnnotationC u s t o m i z e d  M o d e l  T r a i n i n gModel Cust omizationDI A Model HubDI A Pipeline SharingCommunity PlatformLa y out Detection ModelsDocument Images \n",
      "T h e  C o r e  L a y o u t P a r s e r  L i b r a r yOCR ModuleSt or age & VisualizationLa y ou\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "fiass_index = FAISS.from_documents(pages, OpenAIEmbeddings())\n",
    "docs = fiass_index.similarity_search(\"How will the community be engaged?\", k=2)\n",
    "for doc in docs: \n",
    "    print(str(doc.metadata[\"page\"]) + \":\", doc.page_content[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaf4ccb-8433-4a1b-9674-83a7caa74070",
   "metadata": {},
   "source": [
    "## Extracting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "347b3e1b-8dfe-4759-9caa-aad40d6e0245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rapidocr-onnxruntime\n",
      "  Downloading rapidocr_onnxruntime-1.3.9-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting pyclipper>=1.2.0 (from rapidocr-onnxruntime)\n",
      "  Downloading pyclipper-1.3.0.post5-cp310-cp310-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: onnxruntime>=1.7.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rapidocr-onnxruntime) (1.16.3)\n",
      "Collecting opencv-python>=4.5.1.48 (from rapidocr-onnxruntime)\n",
      "  Downloading opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rapidocr-onnxruntime) (1.26.2)\n",
      "Requirement already satisfied: six>=1.15.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rapidocr-onnxruntime) (1.16.0)\n",
      "Collecting Shapely>=1.7.1 (from rapidocr-onnxruntime)\n",
      "  Downloading shapely-2.0.2-cp310-cp310-win_amd64.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rapidocr-onnxruntime) (6.0.1)\n",
      "Collecting Pillow<=10.0.1 (from rapidocr-onnxruntime)\n",
      "  Downloading Pillow-10.0.1-cp310-cp310-win_amd64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (23.5.26)\n",
      "Requirement already satisfied: packaging in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (23.2)\n",
      "Requirement already satisfied: protobuf in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (4.25.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (1.12)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from coloredlogs->onnxruntime>=1.7.0->rapidocr-onnxruntime) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->onnxruntime>=1.7.0->rapidocr-onnxruntime) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\owner\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.7.0->rapidocr-onnxruntime) (3.4.1)\n",
      "Downloading rapidocr_onnxruntime-1.3.9-py3-none-any.whl (14.9 MB)\n",
      "   ---------------------------------------- 0.0/14.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/14.9 MB 7.9 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 1.1/14.9 MB 14.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.8/14.9 MB 26.9 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 5.9/14.9 MB 34.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 5.9/14.9 MB 34.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.0/14.9 MB 25.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.2/14.9 MB 22.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.8/14.9 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.9/14.9 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.9/14.9 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.9/14.9 MB 29.7 MB/s eta 0:00:00\n",
      "Downloading opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "   ---------------------------------------- 0.0/38.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.0/38.1 MB 42.7 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 4.3/38.1 MB 68.4 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 6.9/38.1 MB 62.7 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 9.5/38.1 MB 60.5 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 12.1/38.1 MB 59.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 13.7/38.1 MB 54.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 16.3/38.1 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 18.8/38.1 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 21.0/38.1 MB 46.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 23.7/38.1 MB 54.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 26.2/38.1 MB 54.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 28.6/38.1 MB 50.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 30.7/38.1 MB 54.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 32.7/38.1 MB 46.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.0/38.1 MB 46.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  37.5/38.1 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.1/38.1 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.1/38.1 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.1/38.1 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.1/38.1 MB 27.3 MB/s eta 0:00:00\n",
      "Downloading Pillow-10.0.1-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 64.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 MB 32.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 23.0 MB/s eta 0:00:00\n",
      "Downloading pyclipper-1.3.0.post5-cp310-cp310-win_amd64.whl (108 kB)\n",
      "   ---------------------------------------- 0.0/108.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 108.2/108.2 kB 6.5 MB/s eta 0:00:00\n",
      "Downloading shapely-2.0.2-cp310-cp310-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------  1.4/1.4 MB 89.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 30.4 MB/s eta 0:00:00\n",
      "Installing collected packages: pyclipper, Shapely, Pillow, opencv-python, rapidocr-onnxruntime\n",
      "Successfully installed Pillow-10.0.1 Shapely-2.0.2 opencv-python-4.8.1.78 pyclipper-1.3.0.post5 rapidocr-onnxruntime-1.3.9\n"
     ]
    }
   ],
   "source": [
    "!pip install rapidocr-onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a32a01d1-7324-4a5f-a6bc-6a4104bb1baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LayoutParser : A Uniﬁed Toolkit for DL-Based DIA 5\\nTable 1: Current layout detection models in the LayoutParser model zoo\\nDataset Base Model1Large Model Notes\\nPubLayNet [38] F / M M Layouts of modern scientiﬁc documents\\nPRImA [3] M - Layouts of scanned modern magazines and scientiﬁc reports\\nNewspaper [17] F - Layouts of scanned US newspapers from the 20th century\\nTableBank [18] F F Table region on modern scientiﬁc and business document\\nHJDataset [31] F / M - Layouts of history Japanese documents\\n1For each dataset, we train several models of diﬀerent sizes for diﬀerent needs (the trade-oﬀ between accuracy\\nvs. computational cost). For “base model” and “large model”, we refer to using the ResNet 50 or ResNet 101\\nbackbones [ 13], respectively. One can train models of diﬀerent architectures, like Faster R-CNN [ 28] (F) and Mask\\nR-CNN [ 12] (M). For example, an F in the Large Model column indicates it has a Faster R-CNN model trained\\nusing the ResNet 101 backbone. The platform is maintained and a number of additions will be made to the model\\nzoo in coming months.\\nlayout data structures , which are optimized for eﬃciency and versatility. 3) When\\nnecessary, users can employ existing or customized OCR models via the uniﬁed\\nAPI provided in the OCR module . 4)LayoutParser comes with a set of utility\\nfunctions for the visualization and storage of the layout data. 5) LayoutParser\\nis also highly customizable, via its integration with functions for layout data\\nannotation and model training . We now provide detailed descriptions for each\\ncomponent.\\n3.1 Layout Detection Models\\nInLayoutParser , a layout model takes a document image as an input and\\ngenerates a list of rectangular boxes for the target content regions. Diﬀerent\\nfrom traditional methods, it relies on deep convolutional neural networks rather\\nthan manually curated rules to identify content regions. It is formulated as an\\nobject detection problem and state-of-the-art models like Faster R-CNN [ 28] and\\nMask R-CNN [ 12] are used. This yields prediction results of high accuracy and\\nmakes it possible to build a concise, generalized interface for layout detection.\\nLayoutParser , built upon Detectron2 [ 35], provides a minimal API that can\\nperform layout detection with only four lines of code in Python:\\n1import layoutparser as lp\\n2image = cv2. imread (\" image_file \") # load images\\n3model = lp. Detectron2LayoutModel (\\n4 \"lp :// PubLayNet / faster_rcnn_R_50_FPN_3x / config \")\\n5layout = model . detect ( image )\\nLayoutParser provides a wealth of pre-trained model weights using various\\ndatasets covering diﬀerent languages, time periods, and document types. Due to\\ndomain shift [ 7], the prediction performance can notably drop when models are ap-\\nplied to target samples that are signiﬁcantly diﬀerent from the training dataset. As\\ndocument structures and layouts vary greatly in diﬀerent domains, it is important\\nto select models trained on a dataset similar to the test samples. A semantic syntax\\nis used for initializing the model weights in LayoutParser , using both the dataset\\nname and model name lp://<dataset-name>/<model-architecture-name> .'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"https://arxiv.org/pdf/2103.15348.pdf\", extract_images=True)\n",
    "pages = loader.load()\n",
    "pages[4].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ee9808-063c-4794-957b-b3dcdeba0957",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eabbacc5-b76f-4488-9dd4-d746fed3bddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import MathpixPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2a869a5-c537-4a7a-8c88-e15508a7535f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Did not find mathpix_api_key, please add an environment variable `MATHPIX_API_KEY` which contains it, or pass  `mathpix_api_key` as a named parameter.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[43mMathpixPDFLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/Users/Owner/GenAI/LCEL/data/layout-parser-paper.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_community\\document_loaders\\pdf.py:400\u001b[0m, in \u001b[0;36mMathpixPDFLoader.__init__\u001b[1;34m(self, file_path, processed_file_format, max_wait_time_seconds, should_clean_pdf, extra_request_data, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    382\u001b[0m     file_path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    388\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize with a file path.\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;124;03m        **kwargs: additional keyword arguments.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmathpix_api_key \u001b[38;5;241m=\u001b[39m \u001b[43mget_from_dict_or_env\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmathpix_api_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMATHPIX_API_KEY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmathpix_api_id \u001b[38;5;241m=\u001b[39m get_from_dict_or_env(\n\u001b[0;32m    404\u001b[0m         kwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmathpix_api_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMATHPIX_API_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    405\u001b[0m     )\n\u001b[0;32m    407\u001b[0m     \u001b[38;5;66;03m# The base class isn't expecting these and doesn't collect **kwargs\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\utils\\env.py:31\u001b[0m, in \u001b[0;36mget_from_dict_or_env\u001b[1;34m(data, key, env_key, default)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data[key]\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_from_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\utils\\env.py:41\u001b[0m, in \u001b[0;36mget_from_env\u001b[1;34m(key, env_key, default)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDid not find \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, please add an environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` which contains it, or pass\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` as a named parameter.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     45\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Did not find mathpix_api_key, please add an environment variable `MATHPIX_API_KEY` which contains it, or pass  `mathpix_api_key` as a named parameter."
     ]
    }
   ],
   "source": [
    "loader = MathpixPDFLoader(\"C:/Users/Owner/GenAI/LCEL/data/layout-parser-paper.pdf\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02ad40a-7fb8-494e-9dc2-a108a89add01",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredPDFLoader(\"example_data/layout-parser-paper.pdf\", mode=\"elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc221f2c-9087-4d71-a7f1-4f1b0d575f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70edde6d-a5da-4a50-811a-00fe025d61b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
